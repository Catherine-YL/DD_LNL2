nohup: ignoring input
Hyper-parameters: 
 {'dataset': 'CIFAR10', 'data_path': '../../dataset', 'batch_real': 256, 'subset': 'imagenette', 'model': 'ConvNet', 'dsa': True, 'dsa_strategy': 'color_crop_cutout_flip_scale_rotate', 'noise_type': 'symmetric', 'noise_rate': 0.2, 'noise_path': None, 'is_annot': False, 'is_human': False, 'is_coarse': False, 'zca': True, 'train_dvrl': True, 'inner_batch_size': 256, 'inner_iteration': 10, 'inner_learning_rate': 0.001, 'hidden_dim': 100, 'comb_dim': 10, 'outer_iterations': 2000, 'layer_number': 5, 'batch_size': 2000, 'learning_rate': 0.01, 'epsilon': 1e-08, 'threshold': 0.9, 'log_path': '../logs/CIFAR10/ConvNet/symmetric_0.2', 'save_epoch': 50, 'ori_epoch': 5, 'val_epoch': 10, 'device': 'cuda', 'dsa_param': <utils.utils_gsam.ParamDiffAug object at 0x7f9667277b80>}
Files already downloaded and verified
Actual noise 0.20
over all noise rate is  0.20076
Files already downloaded and verified
Train ZCA
  0%|          | 0/50000 [00:00<?, ?it/s]  2%|▏         | 880/50000 [00:00<00:05, 8791.56it/s]  4%|▎         | 1760/50000 [00:00<00:06, 7943.49it/s]  5%|▌         | 2560/50000 [00:00<00:06, 7509.32it/s]  7%|▋         | 3385/50000 [00:00<00:05, 7778.61it/s]  8%|▊         | 4223/50000 [00:00<00:05, 7984.09it/s] 10%|█         | 5046/50000 [00:00<00:05, 8061.69it/s] 12%|█▏        | 5855/50000 [00:00<00:05, 7489.10it/s] 13%|█▎        | 6613/50000 [00:00<00:06, 7122.36it/s] 15%|█▍        | 7333/50000 [00:00<00:06, 6775.52it/s] 16%|█▌        | 8017/50000 [00:01<00:06, 6539.55it/s] 17%|█▋        | 8676/50000 [00:01<00:06, 6488.08it/s] 19%|█▊        | 9328/50000 [00:01<00:06, 6468.23it/s] 20%|██        | 10099/50000 [00:01<00:05, 6822.63it/s] 22%|██▏       | 10927/50000 [00:01<00:05, 7243.26it/s] 23%|██▎       | 11656/50000 [00:01<00:05, 6701.09it/s] 25%|██▍       | 12336/50000 [00:01<00:05, 6660.82it/s] 26%|██▋       | 13168/50000 [00:01<00:05, 7127.77it/s] 28%|██▊       | 14002/50000 [00:01<00:04, 7475.68it/s] 30%|██▉       | 14807/50000 [00:02<00:04, 7640.49it/s] 31%|███       | 15577/50000 [00:02<00:04, 7634.09it/s] 33%|███▎      | 16345/50000 [00:02<00:04, 7528.45it/s] 34%|███▍      | 17117/50000 [00:02<00:04, 7583.70it/s] 36%|███▌      | 17955/50000 [00:02<00:04, 7817.36it/s] 38%|███▊      | 18784/50000 [00:02<00:03, 7956.39it/s] 39%|███▉      | 19599/50000 [00:02<00:03, 8012.57it/s] 41%|████      | 20402/50000 [00:02<00:03, 7881.73it/s] 42%|████▏     | 21192/50000 [00:02<00:03, 7472.18it/s] 44%|████▍     | 21945/50000 [00:02<00:03, 7341.46it/s] 46%|████▌     | 22790/50000 [00:03<00:03, 7655.52it/s] 47%|████▋     | 23560/50000 [00:03<00:03, 7536.20it/s] 49%|████▊     | 24317/50000 [00:03<00:03, 7215.77it/s] 50%|█████     | 25158/50000 [00:03<00:03, 7552.43it/s] 52%|█████▏    | 26000/50000 [00:03<00:03, 7801.88it/s] 54%|█████▎    | 26823/50000 [00:03<00:02, 7903.87it/s] 55%|█████▌    | 27617/50000 [00:03<00:02, 7807.16it/s] 57%|█████▋    | 28401/50000 [00:03<00:02, 7342.54it/s] 58%|█████▊    | 29142/50000 [00:04<00:03, 6054.57it/s] 60%|█████▉    | 29963/50000 [00:04<00:03, 6589.98it/s] 62%|██████▏   | 30793/50000 [00:04<00:02, 7038.18it/s] 63%|██████▎   | 31555/50000 [00:04<00:02, 7194.68it/s] 65%|██████▍   | 32307/50000 [00:04<00:02, 7283.80it/s] 66%|██████▌   | 33054/50000 [00:04<00:02, 7050.07it/s] 68%|██████▊   | 33791/50000 [00:04<00:02, 7139.42it/s] 69%|██████▉   | 34619/50000 [00:04<00:02, 7464.44it/s] 71%|███████   | 35446/50000 [00:04<00:01, 7697.52it/s] 73%|███████▎  | 36264/50000 [00:04<00:01, 7837.82it/s] 74%|███████▍  | 37053/50000 [00:05<00:01, 7845.30it/s] 76%|███████▌  | 37867/50000 [00:05<00:01, 7930.50it/s] 77%|███████▋  | 38690/50000 [00:05<00:01, 8017.99it/s] 79%|███████▉  | 39522/50000 [00:05<00:01, 8105.33it/s] 81%|████████  | 40335/50000 [00:05<00:01, 8110.97it/s] 82%|████████▏ | 41148/50000 [00:05<00:01, 7813.97it/s] 84%|████████▍ | 41974/50000 [00:05<00:01, 7943.30it/s] 86%|████████▌ | 42829/50000 [00:05<00:00, 8119.87it/s] 87%|████████▋ | 43675/50000 [00:05<00:00, 8218.86it/s] 89%|████████▉ | 44522/50000 [00:05<00:00, 8291.94it/s] 91%|█████████ | 45353/50000 [00:06<00:00, 7974.02it/s] 92%|█████████▏| 46154/50000 [00:06<00:00, 7514.60it/s] 94%|█████████▍| 47003/50000 [00:06<00:00, 7786.66it/s] 96%|█████████▌| 47863/50000 [00:06<00:00, 8018.92it/s] 97%|█████████▋| 48697/50000 [00:06<00:00, 8111.95it/s] 99%|█████████▉| 49513/50000 [00:06<00:00, 7604.27it/s]100%|██████████| 50000/50000 [00:06<00:00, 7493.81it/s]
Test ZCA
  0%|          | 0/10000 [00:00<?, ?it/s]  8%|▊         | 795/10000 [00:00<00:01, 7943.55it/s] 16%|█▌        | 1601/10000 [00:00<00:01, 8005.96it/s] 24%|██▍       | 2402/10000 [00:00<00:01, 7066.84it/s] 33%|███▎      | 3289/10000 [00:00<00:00, 7724.35it/s] 42%|████▏     | 4169/10000 [00:00<00:00, 8091.12it/s] 51%|█████     | 5061/10000 [00:00<00:00, 8362.76it/s] 60%|█████▉    | 5952/10000 [00:00<00:00, 8535.82it/s] 68%|██████▊   | 6840/10000 [00:00<00:00, 8643.31it/s] 77%|███████▋  | 7709/10000 [00:00<00:00, 8571.18it/s] 86%|████████▌ | 8575/10000 [00:01<00:00, 8597.34it/s] 94%|█████████▍| 9440/10000 [00:01<00:00, 8610.30it/s]100%|██████████| 10000/10000 [00:01<00:00, 8346.93it/s]
resuming by loading epoch 50
Initialize DVRL class
resuming by loading epoch 5
resuming by loading epoch 10
resuming by loading epoch 1
Origin model Performance F1: 0.640000
/home/wxy/anaconda3/envs/dd/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
At epoch 0, the reward is -0.090000, the prob is 0.252493
At epoch 1, the reward is -0.540000, the prob is 0.000639
At epoch 2, the reward is -0.548000, the prob is 0.000000
At epoch 3, the reward is -0.548000, the prob is 0.000000
